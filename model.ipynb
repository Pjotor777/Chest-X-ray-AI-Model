{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4182b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader, random_split, Subset\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "#import zipfile # for unzipping the dataset - not needed in the end, pics unzipped locally in folder spr-x-ray\n",
    "import os\n",
    "import time\n",
    "# ===================================================================================================================================\n",
    "# Final Project: Part 2\n",
    "# Design and implement a single hidden layer shallow fully connected network for performing both the regression (age) and \n",
    "# classification (male/female) tasks, and report on their regression/classification performance.\n",
    "# ===================================================================================================================================\n",
    "# Part 0: Initialize Device (CUDA)\n",
    "# GPU used on my personal device: GeForce GTX 1660 Ti\n",
    "USE_CUDA = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
    "print(f\"Part 0: Using device: {device}\")\n",
    "print(\"=========================================\\n\")\n",
    "# ===================================================================================================================================\n",
    "# Part 1: Load  and preprocess Data\n",
    "# Define the path for the CSVs and the PNG images\n",
    "image_dir = \"./spr-x-ray/train\"\n",
    "# Load the CSVs properly\n",
    "# Load the CSVs\n",
    "age_df = pd.read_csv(\"train_age.csv\")\n",
    "gender_df = pd.read_csv(\"train_gender.csv\")\n",
    "\n",
    "# Check column names\n",
    "#print(\"Age CSV columns:\", age_df.columns.tolist())\n",
    "#print(\"Gender CSV columns:\", gender_df.columns.tolist())\n",
    "\n",
    "# merge the CSV's for processing\n",
    "labels_ag = pd.merge(age_df, gender_df, on='imageId')\n",
    "# Create correct filenames (zero-padded to match files like 000000.png)\n",
    "labels_ag['filename'] = labels_ag['imageId'].astype(str).str.zfill(6) + \".png\"\n",
    "# Keep only needed columns\n",
    "labels_ag = labels_ag[['filename', 'age', 'gender']]\n",
    "\n",
    "# Confirm merge was properly executed\n",
    "print(\"Merged and processed labels:\", labels_ag.shape)\n",
    "print(labels_ag.head()) # default: prints first 5 rows\n",
    "print(labels_ag.tail(10))   # Shows last 10\n",
    "print(\"=========================================\\n\")\n",
    "\n",
    "# Define transform for grayscale X-rays (e.g., resize, normalize)\n",
    "png_transform = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),       # Resize from 1024x1024 to 224x224 or 128x128. 224x224 clogs cpu, do 128x128\n",
    "    transforms.ToTensor(),               # Convert to tensor\n",
    "    transforms.Normalize([0.5], [0.5])   # Normalize grayscale [mean], [std]\n",
    "])\n",
    "# ===================================================================================================================================\n",
    "# Part 2: Create custom class to load images and labels, read and transform the image files, and\n",
    "# utilizes DataLoader (via pytorch) to batch/shuffle/load data during training\n",
    "\n",
    "# Define custom dataset class as stated previously\n",
    "class ChestXrayDataset(Dataset):\n",
    "    # Initialize the class\n",
    "    def __init__(self, dataframe, image_dir, transform=None):\n",
    "        self.data = dataframe # containing image filenames and labels\n",
    "        self.image_dir = image_dir # image folder directory\n",
    "        self.transform = transform # image transform for application\n",
    "\n",
    "    def __len__(self): # Get  length of the dataset\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx): # Get item from the dataset\n",
    "        row = self.data.iloc[idx] # Get row of data\n",
    "        img_path = os.path.join(self.image_dir, row['filename']) # Get image path\n",
    "        image = Image.open(img_path).convert('L')  # If path exists, convert to grayscale\n",
    "\n",
    "        if self.transform: # Apply transform if provided\n",
    "            image = self.transform(image) # resize + normalize image\n",
    "\n",
    "        # convert to pytorch sensors\n",
    "        age = torch.tensor(row['age'], dtype=torch.float32) # convert age value to float32\n",
    "        gender = torch.tensor(row['gender'], dtype=torch.float32)  # BCEWithLogitsLoss expects float\n",
    "        # return image with corresponging values\n",
    "        # transformed image tensor: shape [1, 224, 224]\n",
    "        return image, age, gender\n",
    "# end class\n",
    "\n",
    "# Create full dataset object (all images)\n",
    "dataset = ChestXrayDataset(labels_ag, image_dir=image_dir, transform=png_transform) \n",
    "# Limit dataset to subset (for speed)\n",
    "#subset_size = 2000 # try 500, 1k or 2k\n",
    "#full_dataset = ChestXrayDataset(labels_ag, image_dir=image_dir, transform=png_transform)\n",
    "#dataset = Subset(full_dataset, range(subset_size))\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "#train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=2, pin_memory=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=2, pin_memory=True)\n",
    "# DataLoaders with batch size 64 and 4 workers (for faster training)\n",
    "# Note: pin_memory=True and persistent_workers=True are used for faster data loading on GPU\n",
    "#train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, # default: 4 workers, test 1 to see if it fixes slow startup\n",
    "#                           num_workers= 4, pin_memory=True, persistent_workers=True)\n",
    "#val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False,\n",
    "#                        num_workers=4, pin_memory=True, persistent_workers=True)\n",
    "\n",
    "# issue vixed by pinning memory and using only 1 cpu core (num_worker = 0)\n",
    "train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True,\n",
    "                          num_workers = 0, pin_memory = True)\n",
    "val_loader = DataLoader(val_dataset, batch_size = 64, shuffle = True,\n",
    "                          num_workers = 0, pin_memory = True)\n",
    "# Confirm structure\n",
    "print(f\"Total samples in batch: {len(dataset)}\")\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Validation samples: {len(val_dataset)}\")\n",
    "print(\"=========================================\\n\")\n",
    "# Optional: test one batch - takes WAY TOO LONG, over 15min. Best to leave commented\n",
    "#sample_batch = next(iter(train_loader))\n",
    "#images, ages, genders = sample_batch\n",
    "#print(f\"Batch shapes → Images: {images.shape}, Ages: {ages.shape}, Genders: {genders.shape}\")\n",
    "# ====================================================================================================================================\n",
    "# Part 3: Define and train the model \n",
    "class CNNModel(nn.Module):\n",
    "    def __init__(self): # Initialize the model\n",
    "        super(CNNModel, self).__init__()\n",
    "        self.features = nn.Sequential( # Feature extraction layers\n",
    "            nn.Conv2d(1, 16, kernel_size=3, padding=1), # 1 input channel (grayscale), 16 output channels\n",
    "            nn.BatchNorm2d(16), # Batch normalization\n",
    "            nn.ReLU(), # Activation function\n",
    "            nn.MaxPool2d(2),  # 128 → 64, downsampled by 2. repeat down below\n",
    "\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1), # repeat batch norm, relu, maxpool\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 64 → 32\n",
    "\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2),  # 32 → 16\n",
    "        )\n",
    "\n",
    "        self.flatten = nn.Flatten() # Flatten the output from the convolutional layers\n",
    "        self.fc1 = nn.Linear(64 * 16 * 16, 256) # Fully connected layer\n",
    "        self.dropout = nn.Dropout(0.3) # Dropout for regularization\n",
    "        self.age_output = nn.Linear(256, 1) # Output layer for age regression\n",
    "        self.gender_output = nn.Linear(256, 1) # Output layer\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x) # Pass through feature extraction layers\n",
    "        x = self.flatten(x) # Flatten the output\n",
    "        x = self.fc1(x) # Pass through fully connected layer\n",
    "        x = self.dropout(x) # drop neurons\n",
    "        age = self.age_output(x).squeeze(1) # Output for age regression\n",
    "        gender = self.gender_output(x).squeeze(1) # Outout for gender\n",
    "        return age, gender\n",
    "#end class\n",
    "\n",
    "# Instantiate model\n",
    "model = CNNModel().to(device)\n",
    "\n",
    "# Loss functions and optimizer (with weight decay for regularization)\n",
    "age_loss_fn = nn.MSELoss() # mean square error loss for age regression\n",
    "gender_loss_fn = nn.BCEWithLogitsLoss() # Binary Cross-Entropy with logits loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "#optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay = 1e-6) # default 1e-5,try: 1e-4, 1e-6\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2, verbose=True)\n",
    "\n",
    "\n",
    "num_epochs = 10 # originally at 10, test other vals later. Final verdict: 10 is optimal for all 3 models\n",
    "\n",
    "patience = 5 # Early stopping patience, 5 epochs without improvement\n",
    "best_val_loss = float('inf') # Initialize best validation loss to infinity\n",
    "epochs_no_improve = 0 # Counter for early stopping\n",
    "mae_loss_fn = nn.L1Loss() # Mean Absolute Error (MAE) loss function for age regression\n",
    "\n",
    "# Variables to store performance history\n",
    "train_age_losses = []\n",
    "train_gender_losses = []\n",
    "train_gender_accuracies = []\n",
    "val_age_losses = []\n",
    "val_gender_losses = []\n",
    "val_gender_accuracies = []\n",
    "train_age_mae = []\n",
    "val_age_mae = []\n",
    "\n",
    "#looper = 0\n",
    "#start_time = time.time() # for debugging\n",
    "\n",
    "# Loop for training the model\n",
    "for epoch in range(num_epochs):\n",
    "    model.train() # Set model to training mode\n",
    "    # Reset running loss and accuracy variables\n",
    "    running_age_loss = 0.0\n",
    "    running_gender_loss = 0.0\n",
    "    running_age_mae = 0.0\n",
    "    correct_gender = 0\n",
    "    total_gender = 0\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} training...\") # for debugging/tracking where the model is\n",
    "\n",
    "    #for images, ages, genders in train_loader:\n",
    "    for batch_idx, (images, ages, genders) in enumerate(train_loader): # loop thru batch, not whole dataset\n",
    "        # for debugging\n",
    "        #print(f\" Looper: {looper+1}\")\n",
    "        #looper += 1 # for debugging, not needed otherwise\n",
    "        #if batch_idx == 0: # First batch only\n",
    "            #print(f\"First batch loaded in {time.time() - start_time:.2f} seconds\")\n",
    "\n",
    "        # Move data to device (GPU or CPU)\n",
    "        images = images.to(device) \n",
    "        ages = ages.to(device)\n",
    "        genders = genders.to(device)\n",
    "\n",
    "        predicted_ages, predicted_genders = model(images) # Get predictions from model\n",
    "\n",
    "        # Calculate losses\n",
    "        loss_age = age_loss_fn(predicted_ages, ages)\n",
    "        loss_gender = gender_loss_fn(predicted_genders, genders)\n",
    "        mae_age = mae_loss_fn(predicted_ages, ages) # MEAN SBOLUTE error\n",
    "\n",
    "        loss = loss_age + loss_gender # Total loss\n",
    "\n",
    "        optimizer.zero_grad() # Zero gradients before backward pass\n",
    "        loss.backward() # backwards pass\n",
    "        optimizer.step() # Update weights\n",
    "\n",
    "        # Track training performance\n",
    "        running_age_loss += loss_age.item() * images.size(0)\n",
    "        running_gender_loss += loss_gender.item() * images.size(0)\n",
    "        running_age_mae += mae_age.item() * images.size(0)\n",
    "\n",
    "        # Calculate accuracy\n",
    "        preds = (torch.sigmoid(predicted_genders) > 0.5).float()\n",
    "        correct_gender += (preds == genders).sum().item()\n",
    "        total_gender += genders.size(0) # total number of samples\n",
    "        # Progress update\n",
    "        #processed = (batch_idx + 1) * images.size(0)\n",
    "        #print(f\"   → Batch {batch_idx+1}/{len(train_loader)} | Processed: {processed} samples\", end='\\r')\n",
    "\n",
    "    # calculate average losses and accuracies\n",
    "    train_age_losses.append(running_age_loss / len(train_dataset))\n",
    "    train_gender_losses.append(running_gender_loss / len(train_dataset))\n",
    "    train_gender_accuracies.append(correct_gender / total_gender)\n",
    "    train_age_mae.append(running_age_mae / len(train_dataset)) # add mae calc\n",
    "\n",
    "    # Validation phase\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    # Reset validation loss and accuracy variables\n",
    "    val_age_loss = 0.0 \n",
    "    val_gender_loss = 0.0\n",
    "    correct_gender_val = 0\n",
    "    total_gender_val = 0\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation for validation\n",
    "        for images, ages, genders in val_loader: # loop thru batch, not whole dataset\n",
    "            # Move data to device (GPU or CPU)  \n",
    "            images = images.to(device)\n",
    "            ages = ages.to(device)\n",
    "            genders = genders.to(device)\n",
    "\n",
    "            predicted_ages, predicted_genders = model(images) # Get prediction from the model\n",
    "\n",
    "            loss_age = age_loss_fn(predicted_ages, ages) # Calculate loss for age\n",
    "            loss_gender = gender_loss_fn(predicted_genders, genders)  # gender loss\n",
    "            mae_age = mae_loss_fn(predicted_ages, ages) # mae loss\n",
    "\n",
    "            # Calculate total loss for age gender and mae\n",
    "            val_age_loss += loss_age.item() * images.size(0)\n",
    "            val_gender_loss += loss_gender.item() * images.size(0)\n",
    "            val_age_mae_total += mae_age.item() * images.size(0)\n",
    "\n",
    "            # Calculate accuracy for gender\n",
    "            preds = (torch.sigmoid(predicted_genders) > 0.5).float()\n",
    "            correct_gender_val += (preds == genders).sum().item()\n",
    "            total_gender_val += genders.size(0)\n",
    "    # end the loop\n",
    "    # Calculate average losses and accuracies for validation\n",
    "    val_age_losses.append(val_age_loss / len(val_dataset))\n",
    "    val_gender_losses.append(val_gender_loss / len(val_dataset))\n",
    "    val_gender_accuracies.append(correct_gender_val / total_gender_val)\n",
    "    val_age_mae.append(val_age_mae_total / len(val_dataset)) # add calc for mae\n",
    "\n",
    "    # Step scheduler\n",
    "    scheduler.step(val_age_losses[-1])\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_age_losses[-1] < best_val_loss: # If validation loss improved\n",
    "        best_val_loss = val_age_losses[-1]\n",
    "        epochs_no_improve = 0\n",
    "    else: # If no improvement, increment counter\n",
    "        #print(f\"Validation loss did not improve at epoch {epoch+1}\") # for debugging\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= patience:\n",
    "            #print(f\"Early stopping triggered at epoch {epoch+1}\") #mfor debugging\n",
    "            break\n",
    "\n",
    "    # Logging\n",
    "    #print(f\"Epoch {epoch+1}/{num_epochs} | \"\n",
    "          #f\"Train Age Loss: {train_age_losses[-1]:.4f} | Train Gender Loss: {train_gender_losses[-1]:.4f} | Train Gender Acc: {train_gender_accuracies[-1]*100:.2f}% | \"\n",
    "          #f\"Val Age Loss: {val_age_losses[-1]:.4f} | Val Gender Loss: {val_gender_losses[-1]:.4f} | Val Gender Acc: {val_gender_accuracies[-1]*100:.2f}%\")\n",
    "# end loop\n",
    "\n",
    "print(\"=========================================\\n\")\n",
    "print(\"Final Performance:\")\n",
    "print(f\"Train Age Loss       : {train_age_losses[-1]:.4f}\")\n",
    "print(f\"Train Age MAE        : {train_age_mae[-1]:.4f}\")\n",
    "print(f\"Train Gender Loss    : {train_gender_losses[-1]:.4f}\")\n",
    "print(f\"Train Gender Accuracy: {train_gender_accuracies[-1]*100:.2f}%\")\n",
    "print(f\"Val Age Loss         : {val_age_losses[-1]:.4f}\")\n",
    "print(f\"Val Age MAE          : {val_age_mae[-1]:.4f}\")\n",
    "print(f\"Val Gender Loss      : {val_gender_losses[-1]:.4f}\")\n",
    "print(f\"Val Gender Accuracy  : {val_gender_accuracies[-1]*100:.2f}%\")\n",
    "print(\"=========================================\\n\")\n",
    "# ====================================================================================================================================\n",
    "# Part 4A: Plot the training and validation losses and accuracies\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Age loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_age_losses, label=\"Train Age Loss\")\n",
    "plt.plot(val_age_losses, label=\"Val Age Loss\")\n",
    "plt.title(\"Age Regression Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"MSE Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# Gender accuracy\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_gender_accuracies, label=\"Train Accuracy\")\n",
    "plt.plot(val_gender_accuracies, label=\"Val Accuracy\")\n",
    "plt.title(\"Gender Classification Accuracy\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# =====================================================================================================================================\n",
    "# Part 4B: Plot the training and validation MSE and MAE\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# MSE Loss\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_age_losses, label=\"Train MSE\")\n",
    "plt.plot(val_age_losses, label=\"Val MSE\")\n",
    "plt.title(\"Age Regression - MSE Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "\n",
    "# MAE Loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(train_age_mae, label=\"Train MAE\")\n",
    "plt.plot(val_age_mae, label=\"Val MAE\")\n",
    "plt.title(\"Age Regression - MAE\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Absolute Error\")\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "# ====================================================================================================================================\n",
    "# Part 5: Inference on the full dataset and export predictions to CSV\n",
    "\n",
    "def export_predictions_to_csv(model, dataset, output_file=\"model_predictions.csv\", batch_size=64):\n",
    "    # Runs inference on a trained model and saves the age and gender predictions in CSV format:\n",
    "    # Columns: imageId, age, gender\n",
    "\n",
    "    model.eval() # Set model to evaluation mode\n",
    "    model.to(device) # Move model to device\n",
    "\n",
    "    # Create DataLoader for the full dataset\n",
    "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "    predicted_ages = [] # List to store predicted ages, genders, ids\n",
    "    predicted_genders = []\n",
    "    image_ids = []\n",
    "\n",
    "    with torch.no_grad(): # Disable gradient calculation for inference\n",
    "        for batch in loader: # Get batches of data\n",
    "            images, _, _ = batch\n",
    "            images = images.to(device) # Move images to device\n",
    "\n",
    "            # Forward pass\n",
    "            age_preds, gender_logits = model(images) # Get predictions from model\n",
    "\n",
    "            # Post-process predictions\n",
    "            gender_preds = (torch.sigmoid(gender_logits) > 0.5).int().cpu().numpy().tolist()\n",
    "            age_preds = age_preds.cpu().numpy().tolist()\n",
    "\n",
    "            predicted_ages.extend(age_preds) # Convert to numpy and extend list for age\n",
    "            predicted_genders.extend(gender_preds) # Convert to numpy and extend list again for gender\n",
    "\n",
    "    # Extract imageId (remove '.png') from filename column\n",
    "    image_ids = [dataset.data.iloc[i]['filename'].replace('.png', '') for i in range(len(dataset))]\n",
    "\n",
    "    # Build DataFrame in required format\n",
    "    output_df = pd.DataFrame({\n",
    "        \"imageId\": image_ids,\n",
    "        \"age\": [max(0, round(age)) for age in predicted_ages],  # Round and clamp to 0 Ensuring age is positive integer\n",
    "        \"gender\": predicted_genders  # Already binary, 0 femal or 1 male\n",
    "    })\n",
    "\n",
    "    output_df.to_csv(output_file, index=False)\n",
    "    print(f\"Predictions saved to: {output_file}\")\n",
    "\n",
    "# Call the function  \n",
    "export_predictions_to_csv(model, dataset, output_file=\"model3_predictions.csv\")\n",
    "# end part 3 of Final Project\n",
    "# ===================================================================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ensc413-py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
